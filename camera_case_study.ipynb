{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <b>Geospatial Fellows Program</b> </center>\n",
    "\n",
    "\n",
    "# Identifying High Accuracy Regions in Traffic Camera Images to Enhance the Estimation of Road Traffic Metrics: A Quadtree-based Method and Applications \n",
    "<i>Ningchuan Xiao, Yue Lin</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook illustrates a quadtree-based algorithm to establish the image regions with high vehicle detection accuracy. A case study is presented to demonstrate how the use of these high accuracy regions can produce reliable road traffic metrics from traffic camera images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Outline\n",
    "- [Introduction](#intro)\n",
    "- [Vehicle detector](#det)\n",
    "- [Quadtree-based algorithm for HAIR identification](#hair)  \n",
    "- [References](#ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "Traffic cameras have become an important data source for transportation management and control. However, deriving reliable traffic metrics from the camera feeds is challenging due to the limitations of current vehicle detection techniques, as well as the various camera conditions such as height and resolution. The figure below shows two examples of using a state-of-the-art deep learning detector to identify the vehicles in traffic images. It is clear that vehicles distant from the camera are often too small to be detected. Missed small vehicles tend to result in significant errors in the estimation of road traffic metrics. \n",
    "\n",
    "<img src='./figs/missed.png' width='800'/>\n",
    "\n",
    "In this jupyter notebook, we illustrate a quadtree-based algorithm that continuously partitions the image extent until only regions with high detection accuracy are remained. These regions are referred to as the high-accuracy identification regions (HAIR), which will be used to derive reliable road traffic metrics such as traffic density, flow, and speed. A case study in Central Ohio is presented to demonstrate how the use of HAIR can help to improve the accuracy of traffic density estimates using images from a camera. "
   ]
  },
  {
   "source": [
    "<a id='det'></a>\n",
    "## Vehicle detector\n",
    "\n",
    "The use of HAIR assumes that some object detector is available to identify the vehicles present in the images. In this project, a deep learning model called EfficientDet[<sup>1</sup>](#fn1) is used for vehicle identification. EfficientDet is a family of 8 object detection models (EfficientDet-d0 through d7) which share the same architecture. EfficientDet-d0 is the baseline model, and each of the next model has a larger size measured by its depth (number of layers), width (size of layers), and input image resolution. Two data sets are prepared for model training and evaluation using the feeds from 249 cameras in Central Ohio, which consists of 1,392 and 465 images, respectively. Both data sets are processed through an annotation process where bounding boxes of the vehicles are manually identified. Since the deep learning literature generally suggests the use of a large and diverse training data set to improve detection accuracy, we enrich our training data by two external data sources, STREETS[<sup>2</sup>](#fn2) and WebCamT[<sup>3</sup>](#fn3)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: export saved model.\n",
    "!python new_model_inspect.py --runmode=saved_model \\\n",
    "  --model_name=efficientdet-d3 --ckpt_path=model_dir/archive-d3 \\\n",
    "  --saved_model_dir=model_dir/saved_model \\\n",
    "  --hparams=\"image_size=1280x1024\"\n",
    "\n",
    "# Step 2: do inference with saved model.\n",
    "!python new_model_inspect.py --runmode=saved_model_infer \\\n",
    "  --model_name=efficientdet-d3  \\\n",
    "  --saved_model_dir=model_dir/saved_model  \\\n",
    "  --input_image=data/buckeye_traffic/{imagedir}/*  \\\n",
    "  --output_image_dir=data/buckeye_traffic/{imagedir}_results/"
   ]
  },
  {
   "source": [
    "<a id='hair'></a>\n",
    "## Quadtree-based algorithm for HAIR identification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Unzip data from the sample camera."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('data/sample_cam.zip', 'r') as zipObj:\n",
    "   zipObj.extractall('data')"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "## References\n",
    "<span id=\"fn1\"> Tan, M., Pang, R., Le, Q. V., 2020a. EfficientDet: Scalable and Efficient Object Detection, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 10781–10790. </span>\n",
    "\n",
    "<span id=\"fn2\"> Snyder, C., Do, M.N., 2019. STREETS: A Novel Camera Network Dataset for Traffic Flow, in: Wallach, H., Larochelle, H., Beygelzimer, A., D’Alché-Buc, F., Fox, E., Garnett, R. (Eds.), Advances in Neural Information Processing Systems 32 (NIPS 2019). Curran Associates, Inc., New York, US, pp. 10242–10253. </span>\n",
    "\n",
    "<span id=\"fn3\"> Zhang, S., Wu, G., Costeira, J.P., Moura, J.M.F., 2017. Understanding Traffic Density from Large-Scale Web Camera Data, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Honolulu, HI, USA, pp. 4264–4273. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "interpreter": {
   "hash": "c00fa7b34b3c5b66eff7e79ef51c2365cee2c33a027f789c679999857520ea52"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}